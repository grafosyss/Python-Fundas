{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes by - Kiran A Bendigeri\n",
    "Please Read 'Read me' file.\n",
    "\n",
    "Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Machine learning is about extracting knowledge from data. It is a research field at the\n",
    "intersection of statistics, artificial intelligence, and computer science and is also\n",
    "known as predictive analytics or statistical learning.\n",
    "\n",
    "Python has become the lingua franca for many data science applications. It combines\n",
    "the power of general-purpose programming languages with the ease of use of\n",
    "domain-specific scripting languages like MATLAB or R. Python has libraries for data\n",
    "loading, visualization, statistics, natural language processing, image processing, and\n",
    "more. This vast toolbox provides data scientists with a large array of general- and\n",
    "special-purpose functionality. One of the main advantages of using Python is the abil‐\n",
    "ity to interact directly with the code, using a terminal or other tools like the Jupyter\n",
    "Notebook, which we’ll look at shortly. Machine learning and data analysis are funda‐\n",
    "mentally iterative processes, in which the data drives the analysis. It is essential for\n",
    "these processes to have tools that allow quick iteration and easy interaction.\n",
    "\n",
    "scikit-learn is a very popular tool, and the most prominent Python library for\n",
    "machine learning. It is widely used in industry and academia, and a wealth of tutori‐\n",
    "als and code snippets are available online. scikit-learn works well with a number of\n",
    "other scientific Python tools\n",
    "\n",
    "NumPy is one of the fundamental packages for scientific computing in Python. It\n",
    "contains functionality for multidimensional arrays, high-level mathematical func‐\n",
    "tions such as linear algebra operations and the Fourier transform, and pseudorandom\n",
    "number generators.\n",
    "'''\n",
    "import numpy as np\n",
    "x = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "print(\"x:\\n{}\".format(x))\n",
    "\n",
    "'''\n",
    "SciPy is a collection of functions for scientific computing in Python. It provides,\n",
    "among other functionality, advanced linear algebra routines, mathematical function\n",
    "optimization, signal processing, special mathematical functions, and statistical distri‐\n",
    "butions.'''\n",
    "from scipy import sparse\n",
    "# Create a 2D NumPy array with a diagonal of ones, and zeros everywhere else\n",
    "eye = np.eye(4)\n",
    "print(\"NumPy array:\\n{}\".format(eye))\n",
    "\n",
    "# Convert the NumPy array to a SciPy sparse matrix in CSR format\n",
    "# Only the nonzero entries are stored\n",
    "sparse_matrix = sparse.csr_matrix(eye)\n",
    "print(\"\\nSciPy sparse CSR matrix:\\n{}\".format(sparse_matrix))\n",
    "\n",
    "'''\n",
    "matplotlib is the primary scientific plotting library in Python. It provides functions\n",
    "for making publication-quality visualizations such as line charts, histograms, scatter\n",
    "plots, and so on. \n",
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "# Generate a sequence of numbers from -10 to 10 with 100 steps in between\n",
    "x = np.linspace(-10, 10, 100)\n",
    "# Create a second array using sine\n",
    "y = np.sin(x)\n",
    "# The plot function makes a line chart of one array against another\n",
    "plt.plot(x, y, marker=\"x\")\n",
    "plt.show()\n",
    "\n",
    "'''\n",
    "pandas is a Python library for data wrangling and analysis. It is built around a data\n",
    "structure called the DataFrame\n",
    "'''\n",
    "import pandas as pd\n",
    "# create a simple dataset of people\n",
    "data = {'Name': [\"John\", \"Anna\", \"Peter\", \"Linda\"],\n",
    "                'Location' : [\"New York\", \"Paris\", \"Berlin\", \"London\"],\n",
    "                'Age' : [24, 13, 53, 33]\n",
    "                }\n",
    "data_pandas = pd.DataFrame(data)\n",
    "# IPython.display allows \"pretty printing\" of dataframes\n",
    "# in the Jupyter notebook\n",
    "print(data_pandas)\n",
    "\n",
    "'''version'''\n",
    "import sys\n",
    "print(\"Python version: {}\".format(sys.version))\n",
    "import pandas as pd\n",
    "print(\"pandas version: {}\".format(pd.__version__))\n",
    "import matplotlib\n",
    "print(\"matplotlib version: {}\".format(matplotlib.__version__))\n",
    "import numpy as np\n",
    "print(\"NumPy version: {}\".format(np.__version__))\n",
    "import scipy as sp\n",
    "print(\"SciPy version: {}\".format(sp.__version__))\n",
    "import sklearn\n",
    "print(\"scikit-learn version: {}\".format(sklearn.__version__))\n",
    "\n",
    "'''\n",
    "A First Application: Classifying Iris Species\n",
    "we have measurements for which we know the correct species of iris, this is a\n",
    "supervised learning problem. In this problem, we want to predict one of several\n",
    "options (the species of iris). This is an example of a classifcation problem. The possi‐\n",
    "ble outputs (different species of irises) are called classes. Every iris in the dataset\n",
    "belongs to one of three classes, so this problem is a three-class classification problem.\n",
    "The desired output for a single data point (an iris) is the species of this flower. For a\n",
    "particular data point, the species it belongs to is called its label.\n",
    "\n",
    "The data we will use for this example is the Iris dataset, a classical dataset in machine\n",
    "learning and statistics. It is included in scikit-learn in the datasets module. We\n",
    "can load it by calling the load_iris function:\n",
    "'''\n",
    "#Load Data\n",
    "from sklearn.datasets import load_iris\n",
    "iris_dataset = load_iris()\n",
    "print(\"Keys of iris_dataset: \\n{}\".format(iris_dataset.keys()))\n",
    "print(iris_dataset['DESCR'][:193] + \"\\n...\")\n",
    "print(\"Target names: {}\".format(iris_dataset['target_names']))\n",
    "print(\"Feature names: \\n{}\".format(iris_dataset['feature_names']))\n",
    "print(\"Type of data: {}\".format(type(iris_dataset['data'])))\n",
    "print(\"Shape of data: {}\".format(iris_dataset['data'].shape))\n",
    "print(\"First five columns of data:\\n{}\".format(iris_dataset['data'][:5]))\n",
    "print(\"Type of target: {}\".format(type(iris_dataset['target'])))\n",
    "print(\"Shape of target: {}\".format(iris_dataset['target'].shape))\n",
    "print(\"Target:\\n{}\".format(iris_dataset['target']))\n",
    "'''data is usually denoted with a capital X, while labels are denoted by\n",
    "a lowercase y.\n",
    "train_test_split'''\n",
    "from sklearn.model_selection import train_test_split\n",
    "#import mglearn\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                iris_dataset['data'], iris_dataset['target'], random_state=0)\n",
    "print(\"X_train shape: {}\".format(X_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))\n",
    "print(\"X_test shape: {}\".format(X_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))\n",
    "# create dataframe from data in X_train\n",
    "# label the columns using the strings in iris_dataset.feature_names\n",
    "iris_dataframe = pd.DataFrame(X_train, columns=iris_dataset.feature_names)\n",
    "# create a scatter matrix from the dataframe, color by y_train\n",
    "#grr = pd.plotting.scatter_matrix(iris_dataframe, c=y_train, figsize=(15, 15), marker='o',\n",
    "#                        hist_kwds={'bins': 20}, s=60, alpha=.8, cmap=mglearn.cm3)\n",
    "'''The most important parameter of KNeighbor\n",
    "sClassifier is the number of neighbors, which we will set to 1:'''\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "'''To build the model on the training set, we call the fit method of the knn object'''\n",
    "knn.fit(X_train, y_train)\n",
    "'''We can now make predictions using this model on new data for which we might not\n",
    "know the correct labels. Imagine we found an iris in the wild with a sepal length of\n",
    "5 cm, a sepal width of 2.9 cm, a petal length of 1 cm, and a petal width of 0.2 cm.'''\n",
    "X_new = np.array([[5, 2.9, 1, 0.2]])\n",
    "print(\"X_new.shape: {}\".format(X_new.shape))\n",
    "prediction = knn.predict(X_new)\n",
    "print(\"Prediction: {}\".format(prediction))\n",
    "print(\"Predicted target name: {}\".format(\n",
    "        iris_dataset['target_names'][prediction]))\n",
    "'''\n",
    "Evaluating the model\n",
    "we can make a prediction for each iris in the test data and compare it\n",
    "against its label (the known species). We can measure how well the model works by\n",
    "computing the accuracy, which is the fraction of flowers for which the right species\n",
    "was predicted:'''\n",
    "y_pred = knn.predict(X_test)\n",
    "print(\"Test set predictions:\\n {}\".format(y_pred))\n",
    "print(\"Test set score: {:.2f}\".format(np.mean(y_pred == y_test)))\n",
    "acc =float(format(np.mean(y_pred == y_test)))\n",
    "acc= acc*100\n",
    "print(\"The test set accuracy is about \" +str(acc)+\"%\")\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
